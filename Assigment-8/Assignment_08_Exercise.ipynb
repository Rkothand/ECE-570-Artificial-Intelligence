{"cells":[{"cell_type":"markdown","metadata":{"id":"VMUZcUFP9jrE"},"source":["# ECE 57000 Assignment 8 Exercise\n","\n","Your Name:"]},{"cell_type":"markdown","metadata":{"id":"62iKSbGy-Dcp"},"source":["# Exercise 1: Define classifier that extracts latent representations and visualize representations (**40 points**)\n","\n","The latent (i.e., hidden) representations generated by a deep neural network are very important concept in deep learning since the latent space is where the most significant features of the dataset are learned and extracted.\n","In this homework, we will explore the latent representations of a classifier using clustering and nearest neighbor methods.\n","\n","We provide the code for a simple residual CNN with batchnorm and data loaders.\n","\n","*  Here, we define a neural network block architecture that does batch normalization after each convolution layer and has a skip connection. You can read more about batch normalization and skip connections in these papers https://arxiv.org/pdf/1502.03167.pdf and https://arxiv.org/pdf/1512.03385.pdf, respectively.\n","*  In this neural network, the block networks are designed so that the input dimension and the output dimension stay the same. This may not be an optimal design, but it will help us visualize the latent representation later."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFpgn2P2CnD2","outputId":"d2d335a5-34db-43f0-9f53-863fa7064876","executionInfo":{"status":"ok","timestamp":1699037391745,"user_tz":240,"elapsed":295,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Iwn8TlWUEDZ8","executionInfo":{"status":"ok","timestamp":1699037391745,"user_tz":240,"elapsed":5,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","\n","class SimpleResidualBlock(nn.Module):\n","    def __init__(self, ch_in, mult=4):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(ch_in, mult * ch_in, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(mult * ch_in)\n","\n","        self.conv2 = nn.Conv2d(mult * ch_in, mult * ch_in, kernel_size=3, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(mult * ch_in)\n","\n","        self.conv3 = nn.Conv2d(mult * ch_in, ch_in, kernel_size=3, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(ch_in)\n","\n","    def forward(self, x):\n","        x_ = x.clone()\n","        x_ = torch.relu(self.bn1(self.conv1(x_)))\n","        x_ = torch.relu(self.bn2(self.conv2(x_)))\n","        x_ = torch.relu(self.bn3(self.conv3(x_)))\n","        x = x + x_\n","        return x\n","\n","class SimpleResNet(nn.Module):\n","    def __init__(self, ch_in, n_blocks=3):\n","        super().__init__()\n","        self.residual_layers = nn.ModuleList([SimpleResidualBlock(ch_in) for i in range(n_blocks)])\n","        self.maxpool = nn.MaxPool2d((2, 2))\n","        self.fc = nn.Linear(9, 10)\n","\n","    def forward(self, x):\n","        for residual in self.residual_layers:\n","          x = residual(x)\n","          x = self.maxpool(x)\n","        x = x.view(x.shape[0], -1)  # Unravel tensor dimensions\n","        out = self.fc(x)\n","        return out"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":791},"id":"OkEgqocCm77R","outputId":"9cc6572a-5041-491c-ab1b-6321336048b3","executionInfo":{"status":"ok","timestamp":1699037393712,"user_tz":240,"elapsed":1972,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 238258955.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 129973920.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 52707364.34it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 19761959.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 500x500 with 9 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","\n","# Create MNIST datasets\n","classes = np.arange(10)\n","transform = torchvision.transforms.Compose(\n","  [torchvision.transforms.ToTensor(),\n","   torchvision.transforms.Normalize((0.1307,),(0.3081,))])\n","train_dataset = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST('./data', train=False, download=True, transform=transform)\n","\n","# Create dataloaders\n","batch_size_train, batch_size_test = 64, 128\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)\n","\n","# Show sample images\n","batch_idx, (images, targets) = next(enumerate(train_loader))\n","fig, ax = plt.subplots(3,3,figsize = (5,5))\n","for i in range(3):\n","  for j in range(3):\n","    image = images[i*3+j].permute(1,2,0)\n","    image = image/2 + 0.5\n","    ax[i,j].imshow(image.squeeze(2))\n","    ax[i,j].set_title(f'{classes[targets[i*3+j]]}')\n","    ax[i,j].axis('off')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"838HWgEBED6T"},"source":["### Task 1: Inherit the original model class and define a new function returning the same output with the parent's forward function as well as intermediate representations (including the original input)\n","\n","Specifically, the function below should return the original output from `forward` function of the parent's class and a list of intermediate representations `z_list`. `z_list` should be a Python list with 4 entries corresponding to the original batch and the batch **after each maxpool layer.**\n","\n","\n","Hints:\n","* Because of inheritance, you do not need to implement another `__init__` function.\n","  For those who are not familiar with inheritance, here is the link to get to know\n","  what Inheritance in Python is: https://www.geeksforgeeks.org/inheritance-in-python/.\n","* You will want to do the same computation as the original `forward` function\n","  but add some code to save intermediate representations, i.e., the code should\n","  output exactly the same thing as the original `forward` function but also return\n","  intermediate outputs.\n","* The output of this exercise should be:\n","```\n","Representation z0 batch shape = torch.Size([128, 1, 28, 28])\n","Representation z1 batch shape = torch.Size([128, 1, 14, 14])\n","Representation z2 batch shape = torch.Size([128, 1, 7, 7])\n","Representation z3 batch shape = torch.Size([128, 1, 3, 3])\n","```\n","* We provide a simple example for a linear model below."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"4kmDGE6iszto","executionInfo":{"status":"ok","timestamp":1699037393712,"user_tz":240,"elapsed":42,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["# Trivial example below\n","class AffineModel(nn.Module):\n","    def __init__(self, A, b):\n","        super().__init__()\n","        self.A, self.b = A, b\n","    def forward(self, x):\n","        x = torch.matmul(x, self.A)\n","        return x + self.b\n","class ExtractAffineModel(AffineModel):\n","    def compute_and_extract_representations(self, x):\n","        z_list = [x]\n","        x = torch.matmul(x, self.A)\n","        z_list.append(x)\n","        return x + self.b, z_list"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Xn2DEYXYTCG6","outputId":"d363f224-b043-4575-dfd8-4a9dbe337132","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1699037532315,"user_tz":240,"elapsed":253,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-58a9b651e752>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Check that outputs match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_and_extract_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Outputs should be the same'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Check shapes of representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-58a9b651e752>\u001b[0m in \u001b[0;36mcompute_and_extract_representations\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mz_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mz_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SimpleResNetWithRepresentations' object has no attribute 'layers'"]}],"source":["class SimpleResNetWithRepresentations(SimpleResNet):\n","  def compute_and_extract_representations(self, x):\n","    # ---------- Your code ----------\n","    z_list = [x]\n","    z0 = x\n","    z_list.append(z0)\n","    for layer in self.layers:\n","      z = layer(z0)\n","      z_list.append(z)\n","      z0 = z\n","      out = super().forward(x)\n","      z_list.append(out)\n","\n","    # ---------- End your code ----------\n","    return out, z_list\n","\n","model = SimpleResNetWithRepresentations(ch_in=1)\n","model.to(device)\n","images, labels = next(iter(test_loader)) # get a batch\n","images = images.to(device)\n","# Check that outputs match\n","out, z_list = model.compute_and_extract_representations(images)\n","assert torch.all(model(images) == out), 'Outputs should be the same'\n","# Check shapes of representations\n","assert len(z_list) == 4, 'Should have length of 4'\n","assert torch.all(z_list[0] == images), 'First entry should be original data'\n","for zi, z in enumerate(z_list):\n","  print(f'Representation z{zi} batch shape = {z.shape}')"]},{"cell_type":"markdown","metadata":{"id":"Mxx3QvyQnOwG"},"source":["### Task 2: Train the model\n","\n","Using the train and test functions given above, train `model` for 4 epochs using the Adam optimizer with a learning rate of 0.01."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIDy0DtGsUpk","scrolled":false,"executionInfo":{"status":"aborted","timestamp":1699037393713,"user_tz":240,"elapsed":38,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["def train(epoch, model, optimizer):\n","    model.train() # we need to set the mode for our model\n","    for batch_idx, (images, targets) in enumerate(train_loader):\n","      images = images.to(device)\n","      targets = targets.to(device)\n","      optimizer.zero_grad()\n","      output = model(images)\n","      loss = F.cross_entropy(output, targets) # Here is a typical loss function (negative log likelihood)\n","      loss.backward()\n","      optimizer.step()\n","      if batch_idx % 100 == 0: # We visulize our output every 10 batches\n","        print(f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}] Loss: {loss.item()}')\n","\n","def test(epoch, model):\n","  model.eval() # we need to set the mode for our model\n","  test_loss = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for images, targets in test_loader:\n","      images = images.to(device)\n","      targets = targets.to(device)\n","      output = model(images)\n","      test_loss += F.cross_entropy(output, targets, reduction='sum').item()\n","      pred = output.data.max(1, keepdim=True)[1] # we get the estimate of our result by look at the largest class value\n","      correct += pred.eq(targets.data.view_as(pred)).sum() # sum up the corrected samples\n","  test_loss /= len(test_loader.dataset)\n","  print(f'Test result on epoch {epoch}: Avg loss is {test_loss}, Accuracy: {100.*correct/len(test_loader.dataset)}%')\n","\n","# ----------- <Your code> ---------------\n","\n","# ----------- <End Your code> ---------------"]},{"cell_type":"markdown","metadata":{"id":"b0GFUxvp2I10"},"source":["### Task 3: Visualize the intermediate latent representations\n","\n","*   Plot the representations of 20 images from the test dataset in a supblots grid of shape (20, 4) (code already given for setting up these subplots) where the rows correspond to samples in the dataset and columns correspond to the representations produced by `compute_and_extract_representations`\n","\n","Notes:\n","*   We give code below for normalizing the image and plotting on an axis with a title.\n","*   Make sure to set `model.eval()` when computing because of the batchnorm layers\n","*   No title or ylabel is needed in this case.\n","*   `z_list` is a list of 4 tensors of shape ([B, 1, 28, 28]). **Figure out how to pass through the assertion error and think why the batch dimension cannot be processed together.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5HOWNJNG3M5H","executionInfo":{"status":"aborted","timestamp":1699037393714,"user_tz":240,"elapsed":39,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["def plot_representation(z, ax):\n","  # Normalize image for visualization\n","  assert z.ndim == 3, 'Should be 3 dimensional tensor with C x H x W'\n","  z = (z - z.min())/(z.max() - z.min())\n","  if torch.is_tensor(z):  # Convert torch tensor to numpy if needed\n","    z = z.detach().cpu().numpy()\n","  ax.imshow(z.transpose((1,2,0)).squeeze(2))\n","  # Remove ticks and ticklabels to make plot clean\n","  ax.set_xticks([])\n","  ax.set_yticks([])\n","  ax.set_xticklabels([])\n","  ax.set_yticklabels([])\n","\n","n_show = 20\n","fig, axes_mat = plt.subplots(4, n_show, figsize=[n_show, 4])\n","# ----------- <Your code> ---------------\n","\n","# ----------- End your code ---------------"]},{"cell_type":"markdown","metadata":{"id":"OM0f90T0CnD8"},"source":["Notice how the representations become more and more abstract as the depth increases."]},{"cell_type":"markdown","metadata":{"id":"nfoYSMuNCnD9"},"source":["# Exercise 2: Clustering with different representations (50 points)\n","\n","### Task 1: Create simple numpy arrays of the representations\n","To perform further manipulations in numpy and scikit-learn, we will need to create simple numpy arrays for each representation. We provide the code for merging multiple batches. You will need to provide the code for extracting from the given data loader.\n","\n","* Loop through the data loader and extract representations for each batch\n","* Append the labels and z_list to corresponding lists\n","* Break out of loop when the number extracted is n_extract or greater\n","\n","The output of the merged lists should print the following for both train and test:\n","```\n","Types of merged lists\n","    [<class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>]\n","Shapes of merged lists\n","    [(200, 1, 28, 28), (200, 1, 14, 14), (200, 1, 7, 7), (200, 1, 3, 3)]\n","Shape of merged labels\n","    (200,)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peykYo7ICnD9","executionInfo":{"status":"aborted","timestamp":1699037393715,"user_tz":240,"elapsed":40,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["def extract_numpy_representations(model, data_loader, n_extract):\n","  extracted_z_lists = []\n","  labels_list = []\n","  # ------------- Your code ---------------\n","\n","  # ------------- End your code ---------------\n","  # Check extracted_z_lists (type should be tensor)\n","  print(f'Types of first batch\\n    {[type(z) for z in extracted_z_lists[0]]}')\n","  print(f'Shapes of first batch\\n    {[z.shape for z in extracted_z_lists[0]]}')\n","\n","  # Merge extracted z_lists and labels and make numpy arrays\n","  z_list_merge_np = [\n","    np.vstack([\n","      z_list[i].detach().cpu().numpy()\n","      for z_list in extracted_z_lists\n","    ])[:n_extract]  # Extract up to n_extract\n","    for i in range(len(extracted_z_lists[0]))\n","  ]\n","  print(f'Types of merged lists\\n    {[type(z) for z in z_list_merge_np]}')\n","  print(f'Shapes of merged lists\\n    {[z.shape for z in z_list_merge_np]}')\n","  labels_merged_np = np.concatenate([\n","    labels.detach().cpu().numpy()\n","    for labels in labels_list\n","  ])[:n_extract]  # Extract up to n_extract\n","  print(f'Shape of merged labels\\n    {labels_merged_np.shape}')\n","  return z_list_merge_np, labels_merged_np\n","\n","# Extract train and test samples\n","z_list_train, labels_train = extract_numpy_representations(model, train_loader, n_extract=200)\n","z_list_test, labels_test = extract_numpy_representations(model, test_loader, n_extract=200)\n","# Extract regular train and test\n","x_test = z_list_test[0]\n","x_train = z_list_train[0]"]},{"cell_type":"markdown","metadata":{"id":"kGccSyNDqMZd"},"source":["### Task 2: Perform K-means clustering on different representations\n","\n","In this task, we will perform kmeans clustering on each of the latent representations of the test set and then evaluate the clustering based on the true class labels.\n","A good discussion of clustering metrics can be found in [scikit-learn's documentation on clustering metrics](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation).\n","\n","* Using scikit-learn's [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) estimator, perform kmeans with $k=10$ and `random_state=0` on the latent representations and extract the cluster labels.\n","* Use [`sklearn.metrics.adjusted_rand_score`]() to compute a score to evaluate the clustering based on the true class labels.\n","\n","Notes:\n","* You will need to reshape the tensors into matrices immediately before passing into sklearn functions (you should keep the original data as is so that the images can be plotted, but just reshape immediately before passing into scikit-learn functions). Specifically, the arrays will have shape (B, C, H, W) and you should reshape to (B, C*H*W) before passing to scikit-learn functions.\n","* We provide code for plotting and evaluating your clustering.\n","* Note that clustering is unsupervised. What we're plotting here is the ten different clusters, not the ten different categories of true labels. Thus, the cluster index in the plotted image is not necessarily matched to the true label.\n","* Sometimes the `plot_cluster` will have white boxes if there are less than 5 samples in that cluster. Generally, if you use `n_clusters=10` for the clustering tasks, you will have none or only a few white boxes, which is okay."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I3q1XP8MCnD9","executionInfo":{"status":"aborted","timestamp":1699037393716,"user_tz":240,"elapsed":41,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["def plot_cluster(cluster_labels, z_test, title):\n","  # Plot the top images in each cluster both in original space and latent representation\n","  n_samples_show, n_clusters = 5, 10\n","  nr, nc = n_samples_show, 2*n_clusters\n","  fig, axes_mat = plt.subplots(nr, nc, figsize=np.array([nc, nr])/2)\n","  axes_mat_list = np.split(axes_mat, n_clusters, axis=1)\n","  for ci, axes_mat in enumerate(axes_mat_list): # Loop over clusters\n","    sel = cluster_labels==ci\n","    z_cluster = z_test[sel][:n_samples_show]\n","    x_cluster = x_test[sel][:n_samples_show]\n","    for test_i, (z, x, axes) in enumerate(zip(z_cluster, x_cluster, axes_mat)):\n","      plot_representation(x, axes[0])\n","      plot_representation(z, axes[1])\n","      if ci == 0:\n","        axes[0].set_ylabel(test_i)\n","      if test_i == len(axes_mat)-1:\n","        axes[0].set_xlabel(f'C{ci}x')\n","        axes[1].set_xlabel(f'C{ci}z')\n","  fig.suptitle(title)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xaNvjEyiqL4X","scrolled":false,"executionInfo":{"status":"aborted","timestamp":1699037393717,"user_tz":240,"elapsed":42,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["from sklearn.cluster import KMeans\n","from sklearn.metrics import adjusted_rand_score\n","\n","def cluster_and_score(z, true_labels):\n","  # ----------- <Your code> ---------------\n","\n","  # ----------- <End your code> ---------------\n","  return cluster_labels, score\n","\n","fig = plt.figure(figsize=(2,2))\n","plt.bar([f'z{zi}' for zi in range(len(z_list_test))],\n","        [cluster_and_score(z_test, labels_test)[1] for z_test in z_list_test])\n","plt.ylabel('Score')\n","for zi, z_test in enumerate(z_list_test):\n","  cluster_labels, score = cluster_and_score(z_test, labels_test)\n","  plot_cluster(cluster_labels, z_test, f'Clustering with z{zi}, Score={score:.4f}')\n"]},{"cell_type":"markdown","metadata":{"id":"OEtxrrgHCnD-"},"source":["Notice how the 3x3 pattern for the last representation looks similar across the samples."]},{"cell_type":"markdown","metadata":{"id":"8GaPn4pKCnD-"},"source":["# Exercise 3: Nearest neigbhors methods using representations (10 points)\n","\n","### Task 1: Compute and plot nearest neigbhors in different representations\n","\n","We will now compute the 1 nearest neighbor (i.e., `n_neighbors=1`) of test points compared to train points in different representations.\n","\n","* Loop through the representations for the train and test numpy arrays (i.e., `z_list_train` and `z_list_test`).\n","* For each representaiton from the different layers, compute the *training* indices corresponding to the nearest neighbor of first 15 *testing* indices.\n","* Plot the neighbors by passing the test indices and corresponding nearest neighbor training indices along with the corresponding train and test representations and a title that describes which representation into `plot_neighbor`.\n","\n","Notes:\n","* See note above about reshaping tensors immediately before passing to scikit-learn functions which expect a matrix.\n","* The `sklearn.neighbors.NearestNeighbors` class and the `kneighbors` method may be very helpful. The data that is passed to `fit` will be the training data and the data passed to `kneighbors` should be the new test data.\n","* The test indices should just be `np.arange(15)` assuming that you find the nearest training points for the first 15 points in the test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oT21IGduCnD_","scrolled":false,"executionInfo":{"status":"aborted","timestamp":1699037393717,"user_tz":240,"elapsed":2500,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":["def plot_neigbhor(test_ind, nearest_train_ind, z_test, z_train, title):\n","  '''\n","  Plots the original test image, the test image representation,\n","    the nearest train image representation, the nearest original train image.\n","  '''\n","  assert len(test_ind) == len(nearest_train_ind), 'Test and train indices should be the same length'\n","  n_test = len(test_ind)\n","  fig, axes_mat = plt.subplots(4, n_test, figsize=np.array([n_test, 4])/2)\n","  for test_i, nearest_train_i, axes in zip(test_ind, nearest_train_ind, axes_mat.T):\n","    plot_representation(x_test[test_i], axes[0])\n","    plot_representation(z_test[test_i], axes[1])\n","    plot_representation(z_train[nearest_train_i], axes[2])\n","    plot_representation(x_train[nearest_train_i], axes[3])\n","    if test_i == 0:\n","      for lab, ax in zip(['X Tst', 'Z Tst', 'Z Tr', 'X Tr'], axes):\n","        ax.set_ylabel(lab)\n","  fig.suptitle(title)\n","\n","# --------- Your code ---------\n","\n","# --------- End your code ---------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQR_kS0Msztq","executionInfo":{"status":"aborted","timestamp":1699037393717,"user_tz":240,"elapsed":2499,"user":{"displayName":"Rohith Kothandaraman","userId":"02323129527833107459"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}